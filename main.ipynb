{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeFkOYDxXX22"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BSzBFbAXX25"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxSZdq2EXX26"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "main_dir = 'DATASETS'\n",
        "train_dir = os.path. join(main_dir,'train')\n",
        "test_dir = os.path. join(main_dir,'test')\n",
        "valid_dir = os.path. join(main_dir,'validation')\n",
        "\n",
        "train_animal_dir = os.path.join(train_dir,'animal')\n",
        "train_person_dir = os.path.join(train_dir,'person')\n",
        "train_stopsign_dir=os.path.join(train_dir,'stopsign')\n",
        "train_trafficcones_dir=os.path.join(train_dir,'trafficcones')\n",
        "train_trafficlights_dir=os.path.join(train_dir,'trafficlights')\n",
        "train_blue_dir=os.path.join(train_trafficlights_dir,'blue')\n",
        "train_red_dir=os.path.join(train_trafficlights_dir,'red')\n",
        "train_green_dir=os.path.join(train_trafficlights_dir,'green')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SDQ4i-nXX27",
        "outputId": "93c94baa-3022-4681-be38-c098ccee109d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['9ee6e4ec-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9ef65814-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9f05b37c-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9f150d9a-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9f246a2e-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9f33c708-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9f432806-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9f52e200-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9f623cdc-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg', '9f7198da-ae66-11ec-8c1a-5ca6e6e3ecc8.jpg']\n",
            "['0002a1a2-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '0011fe40-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '0021a49e-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '00312bbc-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '004086de-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '004fe232-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '005f3e12-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '006e98ee-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '007df618-ae6d-11ec-8395-5ca6e6e3ecc8.jpg', '008d5338-ae6d-11ec-8395-5ca6e6e3ecc8.jpg']\n",
            "['002f53ce-afe8-11ec-a6f7-5ca6e6e3ecc8.jpg', '0091511c-afea-11ec-a6f7-5ca6e6e3ecc8.jpg', '00c6053a-afe8-11ec-a6f7-5ca6e6e3ecc8.jpg', '013b1116-afea-11ec-a6f7-5ca6e6e3ecc8.jpg', '013b4fa2-afe8-11ec-a6f7-5ca6e6e3ecc8.jpg', '01aed4b8-afe8-11ec-a6f7-5ca6e6e3ecc8.jpg', '027fbd1c-afe8-11ec-a6f7-5ca6e6e3ecc8.jpg', '02b727be-afea-11ec-a6f7-5ca6e6e3ecc8.jpg', '02e25090-afe7-11ec-a6f7-5ca6e6e3ecc8.jpg', '02fd2748-afe8-11ec-a6f7-5ca6e6e3ecc8.jpg']\n",
            "['10815ba2-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '1090dbfe-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '10a038ba-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '10af9530-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '10bef0d4-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '10ce5678-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '10ddb9d8-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '10ed12ac-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '10fc6da6-ae6f-11ec-8395-5ca6e6e3ecc8.jpg', '110bc940-ae6f-11ec-8395-5ca6e6e3ecc8.jpg']\n",
            "['0016a43c-b024-11ec-b516-5ca6e6e3ecc8.jpg', '008d33f4-b024-11ec-b516-5ca6e6e3ecc8.jpg', '0125ea86-b024-11ec-b516-5ca6e6e3ecc8.jpg', '0183635a-b024-11ec-b516-5ca6e6e3ecc8.jpg', '01cbb70e-b024-11ec-b516-5ca6e6e3ecc8.jpg', '023373da-b024-11ec-b516-5ca6e6e3ecc8.jpg', '0280f8e4-b024-11ec-b516-5ca6e6e3ecc8.jpg', '02e811a0-b024-11ec-b516-5ca6e6e3ecc8.jpg', '0345f040-b024-11ec-b516-5ca6e6e3ecc8.jpg', '03b27d3c-b024-11ec-b516-5ca6e6e3ecc8.jpg']\n",
            "['128af3b8-b018-11ec-b170-5ca6e6e3ecc8-checkpoint.jpg', '128af3b8-b018-11ec-b170-5ca6e6e3ecc8.jpg', '12ff2efe-b018-11ec-b170-5ca6e6e3ecc8-checkpoint.jpg', '12ff2efe-b018-11ec-b170-5ca6e6e3ecc8.jpg', '134f8a5c-b018-11ec-b170-5ca6e6e3ecc8.jpg', '138d7dbc-b018-11ec-b170-5ca6e6e3ecc8-checkpoint.jpg', '138d7dbc-b018-11ec-b170-5ca6e6e3ecc8.jpg', '13ca8da6-b018-11ec-b170-5ca6e6e3ecc8.jpg', '14112734-b018-11ec-b170-5ca6e6e3ecc8.jpg', '143564b4-b018-11ec-b170-5ca6e6e3ecc8.jpg']\n",
            "['0212f1fe-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '029f5cd4-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '039c315c-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '044bfa6a-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '04c1f846-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '052bb920-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '058d6c38-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '06244f90-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '069c8abe-b01b-11ec-b170-5ca6e6e3ecc8.jpg', '0727460e-b01b-11ec-b170-5ca6e6e3ecc8.jpg']\n"
          ]
        }
      ],
      "source": [
        "train_animal_names = os.listdir(train_animal_dir)\n",
        "print(train_animal_names[:10])\n",
        "\n",
        "train_person_names = os.listdir(train_person_dir)\n",
        "print(train_person_names[:10])\n",
        "\n",
        "train_stopsign_names = os.listdir(train_stopsign_dir)\n",
        "print(train_stopsign_names[:10])\n",
        "\n",
        "train_trafficcones_names = os.listdir(train_trafficcones_dir)\n",
        "print(train_trafficcones_names[:10])\n",
        "\n",
        "train_blue_names = os.listdir(train_blue_dir)\n",
        "print(train_blue_names[:10])\n",
        "\n",
        "train_red_names = os.listdir(train_red_dir)\n",
        "print(train_red_names[:10])\n",
        "\n",
        "train_green_names = os.listdir(train_green_dir)\n",
        "print(train_green_names[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-Y8My_xXX29",
        "outputId": "f25c6b98-11de-46f7-c9e0-d197f511bae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 753 images belonging to 5 classes.\n",
            "Found 6850 images belonging to 5 classes.\n",
            "Found 753 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   rotation_range = 40,\n",
        "                                   horizontal_flip = True\n",
        "                                  )\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_generator = validation_datagen.flow_from_directory(valid_dir,\n",
        "                                                         target_size=(56,56),\n",
        "                                                         batch_size = 28,\n",
        "                                                         class_mode = \"categorical\"\n",
        "                                                        )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(56,56),\n",
        "                                                    batch_size = 28,\n",
        "                                                    class_mode = \"categorical\"\n",
        "                                                   )\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(56,56),\n",
        "                                                  batch_size = 28,\n",
        "                                                  class_mode = \"categorical\"\n",
        "                                                 )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R392GNodXX2_",
        "outputId": "2fb0f96d-dab3-49de-e0b0-2ed62143c327"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'animal': 0,\n",
              " 'person': 1,\n",
              " 'stopsign': 2,\n",
              " 'trafficcones': 3,\n",
              " 'trafficlights': 4}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJkfE4HNXX2_",
        "outputId": "6cf530f0-d5e6-4bc4-b796-f9109676be02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 9408)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3000)              28227000  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1000)              3001000   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 5005      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,233,005\n",
            "Trainable params: 31,233,005\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model= models.Sequential([\n",
        "        layers.Flatten(input_shape=(56,56,3)),\n",
        "        layers.Dense(3000, activation='relu'),\n",
        "        layers.Dense(1000, activation='relu'),\n",
        "        layers.Dense(5, activation='softmax')    \n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgVvgPL_XX3A"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "H8CLDCz0XX3B",
        "outputId": "62ee44d6-de3d-4939-84e5-51e898eda2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "245/245 [==============================] - 107s 430ms/step - loss: 3.0053 - accuracy: 0.3723 - val_loss: 1.2318 - val_accuracy: 0.4874\n",
            "Epoch 2/10\n",
            "245/245 [==============================] - 66s 268ms/step - loss: 1.1093 - accuracy: 0.5676 - val_loss: 1.2862 - val_accuracy: 0.5086\n",
            "Epoch 3/10\n",
            "245/245 [==============================] - 63s 258ms/step - loss: 0.9502 - accuracy: 0.6283 - val_loss: 1.1092 - val_accuracy: 0.5458\n",
            "Epoch 4/10\n",
            "245/245 [==============================] - 63s 258ms/step - loss: 0.8619 - accuracy: 0.6574 - val_loss: 0.5390 - val_accuracy: 0.7556\n",
            "Epoch 5/10\n",
            "245/245 [==============================] - 62s 254ms/step - loss: 0.7973 - accuracy: 0.6854 - val_loss: 0.6166 - val_accuracy: 0.7517\n",
            "Epoch 6/10\n",
            "245/245 [==============================] - 61s 249ms/step - loss: 0.7764 - accuracy: 0.6953 - val_loss: 0.7124 - val_accuracy: 0.6932\n",
            "Epoch 7/10\n",
            "245/245 [==============================] - 61s 247ms/step - loss: 0.6603 - accuracy: 0.7434 - val_loss: 0.6763 - val_accuracy: 0.7145\n",
            "Epoch 8/10\n",
            "245/245 [==============================] - 60s 246ms/step - loss: 0.5934 - accuracy: 0.7566 - val_loss: 0.5736 - val_accuracy: 0.7450\n",
            "Epoch 9/10\n",
            "245/245 [==============================] - 62s 254ms/step - loss: 0.6082 - accuracy: 0.7707 - val_loss: 0.6153 - val_accuracy: 0.7331\n",
            "Epoch 10/10\n",
            "245/245 [==============================] - 65s 264ms/step - loss: 0.5606 - accuracy: 0.7765 - val_loss: 0.5094 - val_accuracy: 0.7371\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,validation_data=valid_generator,epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPkoqE_TXX3B"
      },
      "outputs": [],
      "source": [
        "test_loss , test_acc = model.evaluate(test_generator)\n",
        "print('test acc :{} test loss:{}'.format(test_acc,test_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYnQlGBMXX3C"
      },
      "outputs": [],
      "source": [
        "model.save('Object_detection_jetbot_dhruv.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrzzwtdHXX3C"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "AUTO BOT OBJECT DETECTION  DHRUV.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}